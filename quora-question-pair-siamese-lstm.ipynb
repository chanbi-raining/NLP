{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport re\nimport matplotlib.pyplot as plt\nimport seaborn as sns \nimport plotly.express as px\nimport plotly.graph_objects as go\n\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras import layers\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.optimizers import Adadelta\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-04T08:06:37.084411Z","iopub.execute_input":"2022-01-04T08:06:37.084788Z","iopub.status.idle":"2022-01-04T08:06:46.107427Z","shell.execute_reply.started":"2022-01-04T08:06:37.084744Z","shell.execute_reply":"2022-01-04T08:06:46.106449Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/kaggle/input/glove6b/glove.6B.200d.txt\n/kaggle/input/glove6b/glove.6B.50d.txt\n/kaggle/input/glove6b/glove.6B.300d.txt\n/kaggle/input/glove6b/glove.6B.100d.txt\n/kaggle/input/quora-question-pairs/train.csv.zip\n/kaggle/input/quora-question-pairs/sample_submission.csv.zip\n/kaggle/input/quora-question-pairs/test.csv\n/kaggle/input/quora-question-pairs/test.csv.zip\n","output_type":"stream"}]},{"cell_type":"markdown","source":"reference : https://towardsdatascience.com/quora-question-pairs-detecting-text-similarity-using-siamese-networks-a370f039731b","metadata":{}},{"cell_type":"code","source":"dirname = '/kaggle/input/quora-question-pairs/'\nfilename = 'train.csv.zip'\n\ndf = pd.read_csv(os.path.join(dirname, filename))\nprint(df.info())\nprint()\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-04T08:39:16.746295Z","iopub.execute_input":"2022-01-04T08:39:16.746664Z","iopub.status.idle":"2022-01-04T08:39:19.002120Z","shell.execute_reply.started":"2022-01-04T08:39:16.746627Z","shell.execute_reply":"2022-01-04T08:39:19.001256Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nInt64Index: 404287 entries, 0 to 404289\nData columns (total 6 columns):\n #   Column        Non-Null Count   Dtype \n---  ------        --------------   ----- \n 0   id            404287 non-null  int64 \n 1   qid1          404287 non-null  int64 \n 2   qid2          404287 non-null  int64 \n 3   question1     404287 non-null  object\n 4   question2     404287 non-null  object\n 5   is_duplicate  404287 non-null  int64 \ndtypes: int64(4), object(2)\nmemory usage: 21.6+ MB\nNone\n\n","output_type":"stream"},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"   id  qid1  qid2                                          question1  \\\n0   0     1     2  What is the step by step guide to invest in sh...   \n1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n2   2     5     6  How can I increase the speed of my internet co...   \n3   3     7     8  Why am I mentally very lonely? How can I solve...   \n4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n\n                                           question2  is_duplicate  \n0  What is the step by step guide to invest in sh...             0  \n1  What would happen if the Indian government sto...             0  \n2  How can Internet speed be increased by hacking...             0  \n3  Find the remainder when [math]23^{24}[/math] i...             0  \n4            Which fish would survive in salt water?             0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>qid1</th>\n      <th>qid2</th>\n      <th>question1</th>\n      <th>question2</th>\n      <th>is_duplicate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>What is the step by step guide to invest in sh...</td>\n      <td>What is the step by step guide to invest in sh...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>3</td>\n      <td>4</td>\n      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n      <td>What would happen if the Indian government sto...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>5</td>\n      <td>6</td>\n      <td>How can I increase the speed of my internet co...</td>\n      <td>How can Internet speed be increased by hacking...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>7</td>\n      <td>8</td>\n      <td>Why am I mentally very lonely? How can I solve...</td>\n      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>9</td>\n      <td>10</td>\n      <td>Which one dissolve in water quikly sugar, salt...</td>\n      <td>Which fish would survive in salt water?</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"print('ratio of duplicates:', round(df['is_duplicate'].mean()*100, 2))\n\nqids = pd.Series(df['qid1'].to_list() + df['qid2'].to_list())\nprint('total # of questions:', len(np.unique(qids)))\nprint('# of questions appearing multiple times:', np.sum(qids.value_counts() > 1))","metadata":{"execution":{"iopub.status.busy":"2022-01-04T05:41:02.978988Z","iopub.execute_input":"2022-01-04T05:41:02.979775Z","iopub.status.idle":"2022-01-04T05:41:03.564339Z","shell.execute_reply.started":"2022-01-04T05:41:02.979733Z","shell.execute_reply":"2022-01-04T05:41:03.563430Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"ratio of duplicates: 36.92\ntotal # of questions: 537933\n# of questions appearing multiple times: 111780\n","output_type":"stream"}]},{"cell_type":"code","source":"sample = pd.read_csv(os.path.join(dirname, 'sample_submission.csv.zip'))\nsample.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-04T07:34:49.545420Z","iopub.execute_input":"2022-01-04T07:34:49.546008Z","iopub.status.idle":"2022-01-04T07:34:50.054101Z","shell.execute_reply.started":"2022-01-04T07:34:49.545970Z","shell.execute_reply":"2022-01-04T07:34:50.053189Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"   test_id  is_duplicate\n0        0             1\n1        1             1\n2        2             1\n3        3             1\n4        4             1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>test_id</th>\n      <th>is_duplicate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# check baseline\n\ntest_filename = 'test.csv'\ndf_test = pd.read_csv(os.path.join(dirname, test_filename))\np = df['is_duplicate'].mean()\nbaseline = pd.DataFrame({'test_id': df_test['test_id'], 'is_duplicate': p})\nbaseline.to_csv('submission.csv', index=False)\nbaseline.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-04T07:30:50.630747Z","iopub.execute_input":"2022-01-04T07:30:50.631504Z","iopub.status.idle":"2022-01-04T07:31:05.646528Z","shell.execute_reply.started":"2022-01-04T07:30:50.631457Z","shell.execute_reply":"2022-01-04T07:31:05.645659Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"   test_id  is_duplicate\n0        0      0.369198\n1        1      0.369198\n2        2      0.369198\n3        3      0.369198\n4        4      0.369198","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>test_id</th>\n      <th>is_duplicate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.369198</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.369198</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0.369198</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0.369198</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0.369198</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Score: 0.55525","metadata":{}},{"cell_type":"markdown","source":"## Train data preprocessing","metadata":{}},{"cell_type":"code","source":"import nltk\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\n\nstop_words = set(stopwords.words('english'))\n\ndef no_abbv(phrase):\n    pharse = phrase.lower()\n    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n    phrase = re.sub(r\"can\\'t\", \"cannot\", phrase)\n    \n    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n    phrase = re.sub(r\"\\'s'\", \" \", phrase)\n    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n    phrase = re.sub(r\"e-mail\", \" email\", phrase)\n    phrase = re.sub(r\" e.g. \", \"  eg \", phrase)\n    phrase = re.sub(r\" u.s. \", \"  american \", phrase)\n    \n    phrase = re.sub(r\"[^A-Za-z0-9]+\", \" \", phrase)\n    \n    return phrase.strip()\n\n\ndef remove_stopwords(phrase):\n    words = word_tokenize(phrase)\n    sent = ' '.join(str(j) for j in words if (j not in stop_words) and (len(j) != 1))\n    return sent\n\ndef preprocess_text(phrase):\n    phrase = no_abbv(phrase)\n    return remove_stopwords(phrase)","metadata":{"execution":{"iopub.status.busy":"2022-01-04T08:39:24.374131Z","iopub.execute_input":"2022-01-04T08:39:24.374586Z","iopub.status.idle":"2022-01-04T08:39:25.196467Z","shell.execute_reply.started":"2022-01-04T08:39:24.374521Z","shell.execute_reply":"2022-01-04T08:39:25.195579Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"df = df.dropna()\n\ndf['question1'] = df['question1'].astype('string')\ndf['question2'] = df['question2'].astype('string')\n\ndf['q1_re'] = df['question1'].apply(preprocess_text)\ndf['q2_re'] = df['question2'].apply(preprocess_text)","metadata":{"execution":{"iopub.status.busy":"2022-01-04T08:39:29.294689Z","iopub.execute_input":"2022-01-04T08:39:29.295057Z","iopub.status.idle":"2022-01-04T08:42:13.819596Z","shell.execute_reply.started":"2022-01-04T08:39:29.295019Z","shell.execute_reply":"2022-01-04T08:42:13.818645Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"'What step step guide invest share market india What step step guide invest share market'"},"metadata":{}}]},{"cell_type":"code","source":"df.shape, df[['q1_re', 'q2_re']].drop_duplicates().shape","metadata":{"execution":{"iopub.status.busy":"2022-01-04T08:48:09.904216Z","iopub.execute_input":"2022-01-04T08:48:09.904577Z","iopub.status.idle":"2022-01-04T08:48:10.290950Z","shell.execute_reply.started":"2022-01-04T08:48:09.904537Z","shell.execute_reply":"2022-01-04T08:48:10.290187Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"((404287, 9), (395197, 2))"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_tmp, X_test, y_tmp, y_test = train_test_split(df[['q1_re', 'q2_re']], df['is_duplicate'], \n                                                test_size=0.2, random_state=24)\nX_train, X_val, y_train, y_val = train_test_split(X_tmp, y_tmp, test_size=0.2, random_state=24)\n\nprint(X_train.shape)\nprint(y_train.shape)\nprint(X_val.shape)\nprint(y_val.shape)\nprint(X_test.shape)\nprint(y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-01-04T09:03:09.981469Z","iopub.execute_input":"2022-01-04T09:03:09.981865Z","iopub.status.idle":"2022-01-04T09:03:10.258899Z","shell.execute_reply.started":"2022-01-04T09:03:09.981813Z","shell.execute_reply":"2022-01-04T09:03:10.257979Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"(258743, 2)\n(258743,)\n(64686, 2)\n(64686,)\n(80858, 2)\n(80858,)\n","output_type":"stream"}]},{"cell_type":"code","source":"qs = list(X_train['q1_re'].values) + list(X_train['q2_re'].values)\n\nmax_words = 10000\ntok = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n\ntok.fit_on_texts(qs)\n\nsequences = tok.texts_to_sequences(qs)\nsequences = pad_sequences(sequences, maxlen=300, padding='post')\n\n","metadata":{"execution":{"iopub.status.busy":"2022-01-04T08:42:13.913151Z","iopub.execute_input":"2022-01-04T08:42:13.913387Z","iopub.status.idle":"2022-01-04T08:43:02.289444Z","shell.execute_reply.started":"2022-01-04T08:42:13.913358Z","shell.execute_reply":"2022-01-04T08:43:02.288507Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Found 400000 word vectors.\n85401\n","output_type":"stream"}]},{"cell_type":"code","source":"glove_dir = '/kaggle/input/glove6b/'\nembeddings_index = {}\nword_index = len(tok.word_index) + 1\nf = open(os.path.join(glove_dir, 'glove.6B.100d.txt'))\n\nfor line in f:\n    values = line.split()\n    word = values[0]\n    coefs = np.asarray(values[1:], dtype='float32')\n    embeddings_index[word] = coefs\n\nf.close()\n\nprint(f'Found {len(embeddings_index)} word vectors.')\nprint(word_index)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Dense, Flatten, Embedding, Bidirectional, LSTM","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lstm_layer = Bidirectional(LSTM(20, dropout=0.2, recurrent_dropout=0.2))\nemb = Embedding(max_words, embedding_dim, input_length=300, weights=[embedding_matrix], trainable=False)\ninput1 = tf.keras.Input(shape=(300,))\ne1 = emb(input1)\nx1 = lstm_layer(e1)\n\ninput2 = tf.keras.Input(shape=(300,))\ne2 = emb(input2)\nx2 = lstm_layer(e2)\n\nmhd = lambda x: tf.keras.backend.abs(x[0] - x[1])\nmerged = Lambda(function=mhd, output_shape=lamba x: x[0], name='L1_distance')([x1, x2])\npreds = Dense(1, activation='sigmoid')(merged)\nmodel = tf.keras.Model(inputs=[input1, input2], outputs=preds)\nmodel.compile(loss='mse', optimizer='adam')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}